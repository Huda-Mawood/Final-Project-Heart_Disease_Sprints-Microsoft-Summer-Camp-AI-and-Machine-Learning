{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44d312da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "794a1a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
      "97    60    0   4       150   258    0        2      157      0      2.6   \n",
      "82    39    1   3       140   321    0        2      182      0      0.0   \n",
      "167   54    0   2       132   288    1        2      159      1      0.0   \n",
      "288   56    1   2       130   221    0        2      163      0      0.0   \n",
      "71    67    1   4       125   254    1        0      163      0      0.2   \n",
      "\n",
      "     slope   ca  thal  \n",
      "97       2  2.0   7.0  \n",
      "82       1  0.0   3.0  \n",
      "167      1  1.0   3.0  \n",
      "288      1  0.0   7.0  \n",
      "71       2  2.0   7.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AIO\\AppData\\Local\\Temp\\ipykernel_7580\\1365330962.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"ca\"].fillna(df[\"ca\"].mean(), inplace=True)\n",
      "C:\\Users\\AIO\\AppData\\Local\\Temp\\ipykernel_7580\\1365330962.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"thal\"].fillna(df[\"thal\"].mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/heart_disease.csv\")\n",
    "\n",
    "df[\"ca\"].fillna(df[\"ca\"].mean(), inplace=True)\n",
    "df[\"thal\"].fillna(df[\"thal\"].mean(), inplace=True)\n",
    "X = df.drop(\"num\", axis=1)\n",
    "y = df[\"num\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "X_train = pd.DataFrame(X_train, columns=X.columns)\n",
    "X_test = pd.DataFrame(X_test, columns=X.columns)\n",
    "\n",
    "print(type(X_train))  \n",
    "print(X_train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "be26d0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = X.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "categorical_features = X.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8e124fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"LogisticRegression\": (\n",
    "        LogisticRegression(max_iter=5000),\n",
    "        {\"model__C\": [0.01, 0.1, 1, 10], \"model__solver\": [\"lbfgs\", \"liblinear\"]}\n",
    "    ),\n",
    "    \"SVM\": (\n",
    "        SVC(probability=True),\n",
    "        {\"model__C\": [0.1, 1, 10], \"model__kernel\": [\"linear\", \"rbf\"]}\n",
    "    ),\n",
    "    \"RandomForest\": (\n",
    "        RandomForestClassifier(),\n",
    "        {\"model__n_estimators\": [100, 200], \"model__max_depth\": [None, 5, 10]}\n",
    "    ),\n",
    "    \"XGBoost\": (\n",
    "        XGBClassifier(eval_metric=\"mlogloss\", use_label_encoder=False),\n",
    "        {\"model__n_estimators\": [100, 200], \"model__max_depth\": [3, 5, 7]}\n",
    "    )\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e3ba7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AIO\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LogisticRegression Best Params: {'model__C': 1, 'model__solver': 'liblinear'}\n",
      "LogisticRegression Accuracy: 0.6229508196721312\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.94      0.86        33\n",
      "           1       0.38      0.27      0.32        11\n",
      "           2       0.17      0.14      0.15         7\n",
      "           3       0.43      0.43      0.43         7\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.62        61\n",
      "   macro avg       0.35      0.36      0.35        61\n",
      "weighted avg       0.57      0.62      0.59        61\n",
      "\n",
      "\n",
      "SVM Best Params: {'model__C': 1, 'model__kernel': 'rbf'}\n",
      "SVM Accuracy: 0.5409836065573771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.94      0.84        33\n",
      "           1       0.17      0.18      0.17        11\n",
      "           2       0.00      0.00      0.00         7\n",
      "           3       0.00      0.00      0.00         7\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.54        61\n",
      "   macro avg       0.18      0.22      0.20        61\n",
      "weighted avg       0.44      0.54      0.48        61\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AIO\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\AIO\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\AIO\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomForest Best Params: {'model__max_depth': None, 'model__n_estimators': 100}\n",
      "RandomForest Accuracy: 0.5245901639344263\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.91      0.85        33\n",
      "           1       0.00      0.00      0.00        11\n",
      "           2       0.00      0.00      0.00         7\n",
      "           3       0.22      0.29      0.25         7\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.52        61\n",
      "   macro avg       0.20      0.24      0.22        61\n",
      "weighted avg       0.45      0.52      0.49        61\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AIO\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\AIO\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\AIO\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\AIO\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [00:59:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost Best Params: {'model__max_depth': 3, 'model__n_estimators': 200}\n",
      "XGBoost Accuracy: 0.5081967213114754\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82        33\n",
      "           1       0.13      0.18      0.15        11\n",
      "           2       0.17      0.14      0.15         7\n",
      "           3       0.17      0.14      0.15         7\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.51        61\n",
      "   macro avg       0.26      0.26      0.26        61\n",
      "weighted avg       0.50      0.51      0.51        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_models = {}\n",
    "\n",
    "for name, (model, params) in models.items():\n",
    "    pipe = Pipeline(steps=[(\"preprocessor\", preprocessor),\n",
    "                           (\"model\", model)])\n",
    "    grid = GridSearchCV(pipe, param_grid=params, cv=3, scoring=\"accuracy\", n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = grid.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"\\n{name} Best Params: {grid.best_params_}\")\n",
    "    print(f\"{name} Accuracy: {acc}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    best_models[name] = (grid.best_estimator_, acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9508f141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model: LogisticRegression with Accuracy 0.6229508196721312\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../models/final_model.pkl']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_name = max(best_models, key=lambda x: best_models[x][1])\n",
    "best_model, best_acc = best_models[best_model_name]\n",
    "\n",
    "print(f\"\\nBest Model: {best_model_name} with Accuracy {best_acc}\")\n",
    "\n",
    "# Save the pipeline (preprocessing + model)\n",
    "joblib.dump(best_model, \"../models/final_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c70cc9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics saved in results/evaluation_metrics.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "# Evaluate model\n",
    "y_pred = grid.best_estimator_.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Save metrics to file\n",
    "with open(\"../results/evaluation_metrics.txt\", \"w\") as f:\n",
    "    f.write(\"Best Model Parameters:\\n\")\n",
    "    f.write(str(grid.best_params_))\n",
    "    f.write(\"\\n\\n\")\n",
    "    f.write(f\"Accuracy: {acc:.4f}\\n\\n\")\n",
    "    f.write(\"Classification Report:\\n\")\n",
    "    f.write(report)\n",
    "\n",
    "print(\"Metrics saved in results/evaluation_metrics.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe2ef42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
